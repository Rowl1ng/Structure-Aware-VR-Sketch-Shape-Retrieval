model_checkpoint:
    _target_: src.callbacks.custom_callbacks.SelfModelCheckpoint
#    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: "val_acc"      # name of the logged metric which determines when model is improving
    save_top_k: 1           # save k best models (determined by above metric)
    save_last: True         # additionaly always save model from last epoch
    mode: "max"             # can be "max" or "min"
    every_n_val_epochs: 5
    dirpath: checkpoints
    filename: "{val_acc:.3f}-{epoch}"
#    filepath: "checkpoints/{epoch}"


early_stopping:
    _target_: pytorch_lightning.callbacks.early_stopping.EarlyStopping
    monitor: "val_acc"      # name of the logged metric which determines when model is improving
    patience: 100           # how many epochs of not improving until training stops
    mode: "max"             # can be "max" or "min"
    min_delta: 0.0          # minimum change in the monitored metric needed to qualify as an improvement

LearningRateMonitor:
    _target_: pytorch_lightning.callbacks.lr_monitor.LearningRateMonitor
